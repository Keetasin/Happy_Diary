{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ElhPSmbdWjrn"
   },
   "outputs": [],
   "source": [
    "# !pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3994768,
     "status": "ok",
     "timestamp": 1740327268792,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "o6s_OMOMWG0s",
    "outputId": "29bcff2d-e03b-4d5d-a67b-3d8f15141c7f"
   },
   "outputs": [],
   "source": [
    "# thai japan china german\n",
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "\n",
    "def back_translate(text, src='en', mid='ja'):\n",
    "    try:\n",
    "        print(f\"Original: {text}\")\n",
    "        translated = GoogleTranslator(source=src, target=mid).translate(text)\n",
    "        print(f\"Translated to Japanese: {translated}\")\n",
    "        back_translated = GoogleTranslator(source=mid, target=src).translate(translated)\n",
    "        print(f\"Back Translated to English: {back_translated}\\n\")  \n",
    "        return back_translated\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {e}\")\n",
    "        return text  \n",
    "\n",
    "# โหลดข้อมูล\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows\\n\")\n",
    "\n",
    "# เลือกเฉพาะ class ที่มีน้อย (mild, moderate, severe) มาเพิ่มข้อมูล\n",
    "print(\"Filtering underrepresented classes (mild, moderate, severe)...\")\n",
    "df_aug = df[df['label'].isin(['mild', 'moderate', 'severe'])].copy()\n",
    "print(f\"Selected {df_aug.shape[0]} rows for augmentation\\n\")\n",
    "\n",
    "# ใช้ Back Translation\n",
    "print(\"Applying Back Translation...\")\n",
    "df_aug['text'] = df_aug['text'].apply(lambda x: back_translate(x))\n",
    "\n",
    "# รวมข้อมูลใหม่กับข้อมูลเดิม\n",
    "df = pd.concat([df, df_aug])\n",
    "print(f\"New dataset size after augmentation: {df.shape[0]} rows\\n\")\n",
    "\n",
    "# บันทึกข้อมูลที่เพิ่มแล้ว\n",
    "output_file = 'dataset_augmented01.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Augmented dataset saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1740327478692,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "FG-ttc-LWCEj",
    "outputId": "1a6c3856-04dd-40a2-f6c1-3c21b0ca7aaa"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# โหลดข้อมูลจากไฟล์ที่คุณมี\n",
    "file_path = \"dataset_augmented01.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ตรวจสอบข้อมูลเบื้องต้น\n",
    "print(\"ข้อมูลก่อนการทำความสะอาด:\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# ลบแถวที่มีค่าว่าง\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ฟังก์ชันทำความสะอาดข้อความ\n",
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  \n",
    "    text = re.sub(r'@\\w+', '', text)  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# ใช้ฟังก์ชันทำความสะอาดกับคอลัมน์ \"text\"\n",
    "df['text'] = df['text'].astype(str).apply(clean_text)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# บันทึกไฟล์ใหม่หลังการทำความสะอาด\n",
    "cleaned_file_path = \"cleaned_dataset_augmented01.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"\\nข้อมูลถูกทำความสะอาดแล้วและบันทึกเป็นไฟล์ {cleaned_file_path}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1740366535164,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "zJOxbM0DWOuH",
    "outputId": "32e51737-d07c-4fdd-d1ea-208c8a7852a5"
   },
   "outputs": [],
   "source": [
    "# โหลดข้อมูลที่ทำความสะอาดแล้ว\n",
    "cleaned_file_path = \"cleaned_dataset_augmented01.csv\"\n",
    "df_cleaned = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# ตรวจสอบข้อมูลหลังการทำความสะอาด\n",
    "print(\"ข้อมูลหลังการทำความสะอาด:\")\n",
    "print(df_cleaned.head()) \n",
    "print(df_cleaned.info())  \n",
    "print(\"\\nตรวจสอบค่าที่หายไป:\")\n",
    "print(df_cleaned.isnull().sum())  \n",
    "\n",
    "# ตรวจสอบค่าซ้ำซ้อน\n",
    "print(\"\\nตรวจสอบค่าซ้ำซ้อน:\")\n",
    "print(df_cleaned.duplicated().sum())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1060319,
     "status": "ok",
     "timestamp": 1740381130882,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "Mb2vRG5erhIB",
    "outputId": "b25a8dee-cc57-49c4-b34f-f82dead4d0a1"
   },
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "\n",
    "def back_translate(text, src='en', mid1='zh-CN', mid2='de'):\n",
    "    try:\n",
    "        print(f\"Original: {text}\") \n",
    "        translated1 = GoogleTranslator(source=src, target=mid1).translate(text)  \n",
    "        print(f\"Translated to Chinese: {translated1}\")\n",
    "        translated2 = GoogleTranslator(source=mid1, target=mid2).translate(translated1)  \n",
    "        print(f\"Translated to German: {translated2}\")\n",
    "        back_translated = GoogleTranslator(source=mid2, target=src).translate(translated2) \n",
    "        print(f\"Back Translated to English: {back_translated}\\n\")\n",
    "        return back_translated\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating: {e}\")\n",
    "        return text  \n",
    "\n",
    "# โหลดข้อมูล\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('cleaned_dataset_augmented01.csv')\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows\\n\")\n",
    "\n",
    "# นับจำนวนตัวอย่างในแต่ละ class\n",
    "desired_count = 2500\n",
    "label_counts = df['label'].value_counts()\n",
    "print(\"Current label distribution:\")\n",
    "print(label_counts, \"\\n\")\n",
    "\n",
    "# เลือกเฉพาะ class ที่มีน้อยกว่า 2000\n",
    "underrepresented_classes = label_counts[label_counts < desired_count].index.tolist()\n",
    "print(f\"Underrepresented classes: {underrepresented_classes}\\n\")\n",
    "\n",
    "# เพิ่มข้อมูลสำหรับแต่ละ class\n",
    "augmented_data = []\n",
    "for label in underrepresented_classes:\n",
    "    df_class = df[df['label'] == label].copy()\n",
    "    num_needed = desired_count - len(df_class)\n",
    "    print(f\"Augmenting class '{label}' with {num_needed} more samples...\")\n",
    "\n",
    "    while len(augmented_data) < num_needed:\n",
    "        for _, row in df_class.iterrows():\n",
    "            new_text = back_translate(row['text'])\n",
    "            augmented_data.append({'text': new_text, 'label': label})\n",
    "            if len(augmented_data) >= num_needed:\n",
    "                break\n",
    "\n",
    "# สร้าง DataFrame ใหม่จากข้อมูลที่เพิ่ม\n",
    "print(\"Creating augmented DataFrame...\")\n",
    "df_aug = pd.DataFrame(augmented_data)\n",
    "print(f\"Generated {df_aug.shape[0]} new rows.\\n\")\n",
    "\n",
    "# รวมข้อมูลใหม่กับข้อมูลเดิม\n",
    "df = pd.concat([df, df_aug], ignore_index=True)\n",
    "print(\"New label distribution after augmentation:\")\n",
    "print(df['label'].value_counts(), \"\\n\")\n",
    "\n",
    "# บันทึกข้อมูลที่เพิ่มแล้ว\n",
    "output_file = 'dataset_augmented02.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Augmented dataset saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1740381131527,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "LRHQvJPkr7rk",
    "outputId": "b2c98e09-877d-46a3-a406-28f7133e0c5a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# โหลดข้อมูลจากไฟล์ที่คุณมี\n",
    "file_path = \"dataset_augmented02.csv\" \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ตรวจสอบข้อมูลเบื้องต้น\n",
    "print(\"ข้อมูลก่อนการทำความสะอาด:\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "# ลบแถวที่มีค่าว่าง\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ฟังก์ชันทำความสะอาดข้อความ\n",
    "def clean_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text) \n",
    "    text = re.sub(r'@\\w+', '', text) \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    return text\n",
    "\n",
    "# ใช้ฟังก์ชันทำความสะอาดกับคอลัมน์ \"text\"\n",
    "df['text'] = df['text'].astype(str).apply(clean_text)\n",
    "print(\"\\nตรวจสอบค่าซ้ำซ้อน:\")\n",
    "print(df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# บันทึกไฟล์ใหม่หลังการทำความสะอาด\n",
    "cleaned_file_path = \"cleaned_dataset_augmented02.csv\"\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"\\nข้อมูลถูกทำความสะอาดแล้วและบันทึกเป็นไฟล์ {cleaned_file_path}\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1740381131617,
     "user": {
      "displayName": "Keetasin Kongsee",
      "userId": "16591596247660632261"
     },
     "user_tz": -420
    },
    "id": "mcQ_hG-tsJGK",
    "outputId": "d225dced-fa5b-4714-ef7e-3ff034678c29"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# โหลดข้อมูลที่ทำความสะอาดแล้ว\n",
    "cleaned_file_path = \"cleaned_dataset_augmented02.csv\"\n",
    "df_cleaned = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# ตรวจสอบข้อมูลหลังการทำความสะอาด\n",
    "print(\"ข้อมูลหลังการทำความสะอาด:\")\n",
    "print(df_cleaned.head())  #\n",
    "print(df_cleaned.info())  \n",
    "\n",
    "print(\"\\nตรวจสอบค่าที่หายไป:\")\n",
    "print(df_cleaned.isnull().sum())  \n",
    "\n",
    "# ตรวจสอบค่าซ้ำซ้อน\n",
    "print(\"\\nตรวจสอบค่าซ้ำซ้อน:\")\n",
    "print(df_cleaned.duplicated().sum()) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0z6D+cQRW/bmRQFtMrL0c",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
